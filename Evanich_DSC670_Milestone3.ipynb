{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43ae46d-e996-42fd-b123-72a7c9d998af",
   "metadata": {},
   "source": [
    "- Allison Evanich\n",
    "- Week 8 - Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ca226-9e49-4ae8-976a-5f3776397d11",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca1ae7-690a-4c76-8815-db74420329ce",
   "metadata": {},
   "source": [
    "In this milestone, I applied what I‚Äôve learned about fine-tuning generative AI models to create a healthcare-specific model that summarize clinical visit information. The goal is to fine-tune OpenAI‚Äôs gpt-4o-mini-2024-07-18 snapshot to generate structured and concise clinical notes for specialties, such as pediatrics.\n",
    "\n",
    "This work builds on the earlier project idea of a generative AI system that assists clinicians by transforming unstructured visit transcripts into standardized Electronic Health Record (EHR) summaries. While Epic Systems recently introduced Abridge for general note generation, specialty-specific adaptation remains an open challenge.\n",
    "\n",
    "By fine-tuning with domain-specific datasets, I aim to explore how customized generative AI can improve accuracy, context, and relevance in clinical documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13aa454-49c7-4b60-827a-feb1165008d8",
   "metadata": {},
   "source": [
    "- Problem: Clinicians spend a significant portion of their time writing and editing notes in EHR systems. AI-generated summaries can help reduce administrative workload, but general-purpose models often miss specialty-specific context.\n",
    "- Goal: Fine-tune a generative AI model to produce structured clinical summaries tailored to pediatric visits.\n",
    "- Why it matters: Specialty fine-tuning could reduce documentation errors, improve patient communication, and save time in clinical workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a91b9-95cd-4423-a559-8e46956498a7",
   "metadata": {},
   "source": [
    "### Model Design Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccafe6-0190-4a86-b504-16375a9c8436",
   "metadata": {},
   "source": [
    "- **Use case:** Specialty‚Äëaware clinical summaries for Pediatrics.  \n",
    "- **Why fine‚Äëtune:** Teach structure (SOAP) and specialty cues for concise, consistent notes.  \n",
    "- **Data format:** Chat `messages` schema (one JSONL object per line), required by current API.  \n",
    "- **Success criteria:** Structured outputs, brevity, clinical relevance, fewer edits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46269b08-03e7-4dd6-8f54-9ad56ba81aea",
   "metadata": {},
   "source": [
    "### Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fb5e095-44fa-4fda-a1d7-158289e57218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os, json, time, pathlib, re\n",
    "from itertools import islice\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bb46a-a82e-468c-856a-c4bbac4a2193",
   "metadata": {},
   "source": [
    "### Prepare and Convert Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6341e9c-ceea-4463-8e3d-5f3c67f7784b",
   "metadata": {},
   "source": [
    "The following dataset is used for fine-tuning:\n",
    "\n",
    "- Pediatric dataset (20 examples) ‚Äî common childhood symptoms and diagnoses.\n",
    "\n",
    "Each example contains a short visit summary prompt and a structured completion with the standard SOAP (Subjective, Objective, Assessment, Plan) layout.\n",
    "\n",
    "Because OpenAI‚Äôs new fine-tuning API requires the messages schema rather than prompt/completion, the dataset is converted automatically below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93d16070-7bf0-4cef-9a20-5e8f6b3ef2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pediatric_notes_train.jsonl ‚Üí pediatric_notes_train_chat.jsonl\n"
     ]
    }
   ],
   "source": [
    "PEDS_SRC = \"pediatric_notes_train.jsonl\"\n",
    "\n",
    "PEDS_CHAT = \"pediatric_notes_train_chat.jsonl\"\n",
    "\n",
    "print(PEDS_SRC, \"‚Üí\", PEDS_CHAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0523d7f-ba62-4dda-b06c-c3f799743b92",
   "metadata": {},
   "source": [
    "### Convert to Chat `messages` Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf0361a0-1060-484b-be88-8cb93a67aea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 20 ‚Üí pediatric_notes_train_chat.jsonl\n"
     ]
    }
   ],
   "source": [
    "def to_chat_schema(src_path, dst_path):\n",
    "    if not pathlib.Path(src_path).exists():\n",
    "        print(f\"[skip] {src_path} not found ‚Äî skipping conversion\")\n",
    "        return\n",
    "    n = 0\n",
    "    with open(src_path, \"r\", encoding=\"utf-8\") as fin, open(dst_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            msg = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": obj[\"prompt\"]},\n",
    "                    {\"role\": \"assistant\", \"content\": obj[\"completion\"].lstrip()}\n",
    "                ]\n",
    "            }\n",
    "            fout.write(json.dumps(msg, ensure_ascii=False) + \"\\n\")\n",
    "            n += 1\n",
    "    print(f\"Converted {n} ‚Üí {dst_path}\")\n",
    "\n",
    "to_chat_schema(PEDS_SRC, PEDS_CHAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9aa26-c780-4eae-b9e3-39f9b81a9e86",
   "metadata": {},
   "source": [
    "### Preview & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2898353-4448-4de4-8a1f-4969604d49b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview pediatric_notes_train_chat.jsonl:\n",
      "{\"messages\": [{\"role\": \"user\", \"content\": \"Patient: 4-year-old with fever, decreased appetite, cough for 3 days.\\n\\nSummarize:\"}, {\"role\": \"assistant\", \"content\": \"History: 4-year-old presents with 3-day history of fever, cough, decreased appetite. No vomiting or diarrhea. Mild irritability noted.\\n\n",
      "{\"messages\": [{\"role\": \"user\", \"content\": \"Patient: 7-year-old with persistent headache and mild photophobia.\\n\\nSummarize:\"}, {\"role\": \"assistant\", \"content\": \"History: 7-year-old with 3-day headache, mild photophobia, no nausea or vomiting.\\nPhysical Exam: Vitals normal, neurologic exam normal.\\nA\n",
      "------------------------------------------------------------\n",
      "pediatric_notes_train_chat.jsonl: 20 lines OK ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "def preview(path, k=2):\n",
    "    p = pathlib.Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"[warn] {path} missing\")\n",
    "        return\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        print(f\"Preview {path}:\")\n",
    "        for line in islice(f, k):\n",
    "            print(line.rstrip()[:300])\n",
    "        print(\"-\"*60)\n",
    "\n",
    "def full_schema_check(path):\n",
    "    p = pathlib.Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"[warn] {path} missing\")\n",
    "        return\n",
    "    n = 0\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, start=1):\n",
    "            obj = json.loads(line)\n",
    "            assert \"messages\" in obj and isinstance(obj[\"messages\"], list), f\"missing messages at line {i}\"\n",
    "            assert len(obj[\"messages\"]) == 2, f\"expected 2 messages at line {i}\"\n",
    "            assert obj[\"messages\"][0][\"role\"] == \"user\", f\"user role missing at line {i}\"\n",
    "            assert obj[\"messages\"][1][\"role\"] == \"assistant\", f\"assistant role missing at line {i}\"\n",
    "            for m in obj[\"messages\"]:\n",
    "                assert isinstance(m[\"content\"], str) and m[\"content\"].strip(), f\"empty content at line {i}\"\n",
    "            n += 1\n",
    "    print(f\"{path}: {n} lines OK ‚úÖ\")\n",
    "\n",
    "preview(PEDS_CHAT); full_schema_check(PEDS_CHAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9af799-40f6-4667-9762-df5e83e9bef5",
   "metadata": {},
   "source": [
    "### Upload Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31de91f5-fcd3-4877-bd26-b2a2b1fec610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pediatrics file ID: file-DtuyfEq5PMQpBo5Lswfxo2\n"
     ]
    }
   ],
   "source": [
    "peds_file = client.files.create(file=open(PEDS_CHAT, \"rb\"), purpose=\"fine-tune\")\n",
    "print(\"Pediatrics file ID:\", peds_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03fa91-7a52-4c75-9dc0-eb0a7f8dd86b",
   "metadata": {},
   "source": [
    "### Create the Fine‚ÄëTuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73ee7905-f84f-4a59-9c04-4ca1516d39fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pediatrics job ID: ftjob-V5pS9TMMgyiRfWva7yRkna2E\n"
     ]
    }
   ],
   "source": [
    "SNAPSHOT = \"gpt-4o-mini-2024-07-18\"\n",
    "\n",
    "peds_job = client.fine_tuning.jobs.create(\n",
    "    training_file=peds_file.id,\n",
    "    model=SNAPSHOT,\n",
    "    suffix=\"peds-notes-v1\"\n",
    ")\n",
    "\n",
    "print(\"Pediatrics job ID:\", peds_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920e433-e199-4246-adb7-f2cc19f9adf3",
   "metadata": {},
   "source": [
    "### Track the Build (Status + Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "792296e3-837f-471f-a177-de3a15483ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pediatrics status: validating_files\n",
      " info | Validating training file: file-DtuyfEq5PMQpBo5Lswfxo2\n",
      " info | Created fine-tuning job: ftjob-V5pS9TMMgyiRfWva7yRkna2E\n"
     ]
    }
   ],
   "source": [
    "def job_status(job_id):\n",
    "    return client.fine_tuning.jobs.retrieve(job_id).status\n",
    "\n",
    "def list_events(job_id, limit=100):\n",
    "    ev = client.fine_tuning.jobs.list_events(job_id, limit=limit)\n",
    "    for e in ev.data:\n",
    "        print(f\"{e.level:>5} | {e.message}\")\n",
    "\n",
    "print(\"Pediatrics status:\", job_status(peds_job.id)); list_events(peds_job.id, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417fb0d-2c44-4f09-9389-406cbd86ba98",
   "metadata": {},
   "source": [
    "### Poll Until Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6076afd3-4484-4af1-9b45-59639402d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_until_complete(job_id, poll_sec=15, max_min=45):\n",
    "    print(f\"Polling {job_id} every {poll_sec}s (max {max_min} min)\")\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        s = job_status(job_id)\n",
    "        print(\"Status:\", s)\n",
    "        list_events(job_id, 10)\n",
    "        if s in (\"succeeded\",\"failed\",\"cancelled\"):\n",
    "            print(\"Final status:\", s)\n",
    "            break\n",
    "        if time.time() - start > max_min * 60:\n",
    "            print(\"Timed out.\")\n",
    "            break\n",
    "        time.sleep(poll_sec)\n",
    "\n",
    "# wait_until_complete(peds_job.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91544a73-f635-4f9b-9c4b-0ba3a2d9cde2",
   "metadata": {},
   "source": [
    "### Document Metrics (Parse Events for Loss/Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dde48ac-c285-47d5-b234-14a8a95f96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Waiting for ftjob-V5pS9TMMgyiRfWva7yRkna2E ...\n",
      "Status ‚Üí validating_files\n",
      " info | Validating training file: file-DtuyfEq5PMQpBo5Lswfxo2\n",
      " info | Created fine-tuning job: ftjob-V5pS9TMMgyiRfWva7yRkna2E\n",
      "Status ‚Üí running\n",
      " info | Fine-tuning job started\n",
      " info | Files validated, moving job to queued state\n",
      " info | Step 6/100: training loss=1.70\n",
      " info | Step 5/100: training loss=1.52\n",
      " info | Step 4/100: training loss=2.33\n",
      " info | Step 3/100: training loss=2.11\n",
      " info | Step 2/100: training loss=2.24\n",
      " info | Step 1/100: training loss=2.49\n",
      " info | Step 12/100: training loss=1.14\n",
      " info | Step 11/100: training loss=0.77\n",
      " info | Step 10/100: training loss=0.85\n",
      " info | Step 9/100: training loss=0.77\n",
      " info | Step 8/100: training loss=1.20\n",
      " info | Step 7/100: training loss=1.38\n",
      " info | Step 18/100: training loss=0.49\n",
      " info | Step 17/100: training loss=0.58\n",
      " info | Step 16/100: training loss=0.94\n",
      " info | Step 15/100: training loss=0.72\n",
      " info | Step 14/100: training loss=0.84\n",
      " info | Step 13/100: training loss=0.91\n",
      " info | Step 24/100: training loss=0.55\n",
      " info | Step 23/100: training loss=0.57\n",
      " info | Step 22/100: training loss=0.52\n",
      " info | Step 21/100: training loss=0.48\n",
      " info | Step 20/100: training loss=0.46\n",
      " info | Step 19/100: training loss=0.55\n",
      " info | Step 30/100: training loss=0.21\n",
      " info | Step 29/100: training loss=0.29\n",
      " info | Step 28/100: training loss=0.16\n",
      " info | Step 27/100: training loss=0.26\n",
      " info | Step 26/100: training loss=0.19\n",
      " info | Step 25/100: training loss=0.33\n",
      " info | Step 36/100: training loss=0.28\n",
      " info | Step 35/100: training loss=0.45\n",
      " info | Step 34/100: training loss=0.35\n",
      " info | Step 33/100: training loss=0.49\n",
      " info | Step 32/100: training loss=0.28\n",
      " info | Step 31/100: training loss=0.25\n",
      " info | Step 42/100: training loss=0.08\n",
      " info | Step 41/100: training loss=0.11\n",
      " info | Step 40/100: training loss=0.37\n",
      " info | Step 39/100: training loss=0.55\n",
      " info | Step 38/100: training loss=0.43\n",
      " info | Step 37/100: training loss=0.47\n",
      " info | Step 48/100: training loss=0.19\n",
      " info | Step 47/100: training loss=0.04\n",
      " info | Step 46/100: training loss=0.06\n",
      " info | Step 45/100: training loss=0.17\n",
      " info | Step 44/100: training loss=0.18\n",
      " info | Step 43/100: training loss=0.19\n",
      " info | Step 54/100: training loss=0.09\n",
      " info | Step 53/100: training loss=0.08\n",
      " info | Step 52/100: training loss=0.20\n",
      " info | Step 51/100: training loss=0.10\n",
      " info | Step 50/100: training loss=0.09\n",
      " info | Step 49/100: training loss=0.34\n",
      " info | Step 60/100: training loss=0.24\n",
      " info | Step 59/100: training loss=0.30\n",
      " info | Step 58/100: training loss=0.03\n",
      " info | Step 57/100: training loss=0.19\n",
      " info | Step 56/100: training loss=0.10\n",
      " info | Step 55/100: training loss=0.12\n",
      " info | Step 66/100: training loss=0.10\n",
      " info | Step 65/100: training loss=0.09\n",
      " info | Step 64/100: training loss=0.02\n",
      " info | Step 63/100: training loss=0.02\n",
      " info | Step 62/100: training loss=0.05\n",
      " info | Step 61/100: training loss=0.06\n",
      " info | Step 72/100: training loss=0.03\n",
      " info | Step 71/100: training loss=0.04\n",
      " info | Step 70/100: training loss=0.19\n",
      " info | Step 69/100: training loss=0.08\n",
      " info | Step 68/100: training loss=0.14\n",
      " info | Step 67/100: training loss=0.06\n",
      " info | Step 78/100: training loss=0.13\n",
      " info | Step 77/100: training loss=0.06\n",
      " info | Step 76/100: training loss=0.01\n",
      " info | Step 75/100: training loss=0.22\n",
      " info | Step 74/100: training loss=0.03\n",
      " info | Step 73/100: training loss=0.09\n",
      " info | Step 84/100: training loss=0.02\n",
      " info | Step 83/100: training loss=0.11\n",
      " info | Step 82/100: training loss=0.01\n",
      " info | Step 81/100: training loss=0.03\n",
      " info | Step 80/100: training loss=0.03\n",
      " info | Step 79/100: training loss=0.04\n",
      " info | Step 90/100: training loss=0.00\n",
      " info | Step 89/100: training loss=0.01\n",
      " info | Step 88/100: training loss=0.02\n",
      " info | Step 87/100: training loss=0.08\n",
      " info | Step 86/100: training loss=0.02\n",
      " info | Step 85/100: training loss=0.04\n",
      " info | Step 96/100: training loss=0.06\n",
      " info | Step 95/100: training loss=0.03\n",
      " info | Step 94/100: training loss=0.04\n",
      " info | Step 93/100: training loss=0.02\n",
      " info | Step 92/100: training loss=0.05\n",
      " info | Step 91/100: training loss=0.03\n",
      " info | Checkpoint created at step 80\n",
      " info | Checkpoint created at step 60\n",
      " info | Step 100/100: training loss=0.00\n",
      " info | Step 99/100: training loss=0.16\n",
      " info | Step 98/100: training loss=0.07\n",
      " info | Step 97/100: training loss=0.04\n",
      " info | Evaluating model against our usage policies\n",
      " info | New fine-tuned model created\n",
      "Status ‚Üí succeeded\n",
      " info | The job has successfully completed\n",
      " info | Usage policy evaluations completed, model is now enabled for sampling\n",
      " info | Moderation checks for snapshot ft:gpt-4o-mini-2024-07-18:personal:peds-notes-v1:CYD9olYs passed.\n",
      "‚úÖ Final status: succeeded\n",
      "\n",
      "=== Pediatrics Metrics ===\n",
      "Steps reported: 100 (last 1 of 100)\n",
      "No loss reports yet.\n",
      "Pediatrics model: ft:gpt-4o-mini-2024-07-18:personal:peds-notes-v1:CYD9olYs\n",
      "\n",
      "--- Output ---\n",
      "\n",
      "History: 6-year-old with 2-day cough, fever 101¬∞F, no rash.\n",
      "Physical Exam: Vitals: Temp 101¬∞F, lungs clear.\n",
      "Assessment: Likely viral upper respiratory infection.\n",
      "Plan: Supportive care, fluids, antipyretics as needed, monitor for worsening.\n"
     ]
    }
   ],
   "source": [
    "import time, re\n",
    "\n",
    "LOSS_RE = re.compile(r\"train_loss\\s*=\\s*([0-9.]+)\", re.I)\n",
    "STEP_RE = re.compile(r\"Step\\s+([0-9]+)/([0-9]+)\", re.I)\n",
    "\n",
    "def job_status(job_id):\n",
    "    return client.fine_tuning.jobs.retrieve(job_id).status\n",
    "\n",
    "def list_events(job_id, limit=100):\n",
    "    return client.fine_tuning.jobs.list_events(job_id, limit=limit).data\n",
    "\n",
    "def extract_metrics_from_events(events):\n",
    "    steps, losses = [], []\n",
    "    for e in events:\n",
    "        msg = getattr(e, \"message\", \"\") or \"\"\n",
    "        m_step = STEP_RE.search(msg)\n",
    "        if m_step:\n",
    "            steps.append((int(m_step.group(1)), int(m_step.group(2))))\n",
    "        m_loss = LOSS_RE.search(msg)\n",
    "        if m_loss:\n",
    "            losses.append(float(m_loss.group(1)))\n",
    "    return steps, losses\n",
    "\n",
    "def wait_until_complete(job_id, poll_sec=15, max_min=60, show_tail=6):\n",
    "    \"\"\"Polls the job until it reaches succeeded/failed/cancelled.\n",
    "    Prints only on status change or new events.\"\"\"\n",
    "    print(f\"‚è≥ Waiting for {job_id} ...\")\n",
    "    start = time.time()\n",
    "    last_status = None\n",
    "    seen_event_ids = set()\n",
    "\n",
    "    while True:\n",
    "        j = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        status = j.status\n",
    "        if status != last_status:\n",
    "            print(f\"Status ‚Üí {status}\")\n",
    "            last_status = status\n",
    "\n",
    "        # print only new events\n",
    "        evs = list_events(job_id, limit=100)\n",
    "        new_evs = [e for e in evs if e.id not in seen_event_ids]\n",
    "        for e in new_evs[-show_tail:]:\n",
    "            print(f\"{e.level:>5} | {e.message}\")\n",
    "            seen_event_ids.add(e.id)\n",
    "\n",
    "        if status in (\"succeeded\", \"failed\", \"cancelled\"):\n",
    "            print(f\"‚úÖ Final status: {status}\")\n",
    "            return j  # return full job object\n",
    "\n",
    "        if time.time() - start > max_min * 60:\n",
    "            print(\"‚è∞ Timed out; returning latest job object.\")\n",
    "            return j\n",
    "\n",
    "        time.sleep(poll_sec)\n",
    "\n",
    "def summarize_metrics(job_id, label):\n",
    "    evs = list_events(job_id, limit=500)\n",
    "    steps, losses = extract_metrics_from_events(evs)\n",
    "    print(f\"\\n=== {label} Metrics ===\")\n",
    "    if steps:\n",
    "        cur, total = steps[-1]\n",
    "        print(f\"Steps reported: {len(steps)} (last {cur} of {total})\")\n",
    "    else:\n",
    "        print(\"No step reports yet.\")\n",
    "    if losses:\n",
    "        print(f\"Loss points: {len(losses)} | First: {losses[0]:.3f} | Last: {losses[-1]:.3f} | Min: {min(losses):.3f}\")\n",
    "    else:\n",
    "        print(\"No loss reports yet.\")\n",
    "\n",
    "def test_model_from_job(job, prompt, label):\n",
    "    if job.status != \"succeeded\":\n",
    "        print(f\"{label}: model not ready (status = {job.status})\")\n",
    "        return\n",
    "    model = job.fine_tuned_model\n",
    "    print(f\"{label} model: {model}\")\n",
    "    r = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "    )\n",
    "    print(\"\\n--- Output ---\\n\")\n",
    "    print(r.choices[0].message.content)\n",
    "\n",
    "# üî∏ Run the blocking wait for job, then summarize + test\n",
    "peds_done = wait_until_complete(peds_job.id, poll_sec=20, max_min=90)\n",
    "\n",
    "summarize_metrics(peds_job.id, \"Pediatrics\")\n",
    "\n",
    "test_model_from_job(\n",
    "    peds_done,\n",
    "    \"Patient: 6-year-old with 2 days of cough and 101¬∞F fever. Summarize:\",\n",
    "    \"Pediatrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a003dcd-53cf-4c22-9e96-f50bbb4fd93a",
   "metadata": {},
   "source": [
    "### Evaluate the Fine‚ÄëTuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af57baa6-758e-4459-8d3c-95edb03e7763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ft:gpt-4o-mini-2024-07-18:personal:peds-notes-v1:CYD9olYs\n",
      "\n",
      "--- Output ---\n",
      "\n",
      "History: 6-year-old with a 2-day history of cough and fever 101¬∞F. No vomiting or diarrhea.\n",
      "\n",
      "Physical Exam: Mild erythematous pharynx, lungs clear, otherwise normal.\n",
      "\n",
      "Assessment: Viral upper respiratory infection.\n",
      "\n",
      "Plan: Supportive care, fluids, antipyretics as needed, return if symptoms worsen.\n"
     ]
    }
   ],
   "source": [
    "def try_infer(job_id, prompt):\n",
    "    j = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    if j.status != \"succeeded\":\n",
    "        print(\"Model not ready. Status:\", j.status)\n",
    "        return\n",
    "    model = j.fine_tuned_model\n",
    "    print(\"Model:\", model)\n",
    "    resp = client.chat.completions.create(model=model, messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "    print(\"\\n--- Output ---\\n\")\n",
    "    print(resp.choices[0].message.content)\n",
    "\n",
    "try_infer(peds_job.id, \"Patient: 6-year-old with 2 days of cough and 101¬∞F fever. Summarize:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819a444-01e7-4ef7-9d80-d14445731a77",
   "metadata": {},
   "source": [
    "### Track and Document Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f12256-093f-4e2b-a1a0-68e4a6f49ac1",
   "metadata": {},
   "source": [
    "Using list_events() and retrieve(), I can track training progress and metrics such as loss, checkpoint status, and completion time. This is how I documented whether the fine-tuning process worked as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d90dfd-0d55-4d9d-82ac-55648b924225",
   "metadata": {},
   "source": [
    "### Reflection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34aed89-23be-4cb6-bc21-af0780d8a91d",
   "metadata": {},
   "source": [
    "This milestone demonstrated the complete process of fine-tuning a generative AI model using OpenAI‚Äôs platform to support clinical documentation in pediatrics. By preparing structured training data in chat format, validating the dataset schema, and tracking model performance through fine-tuning endpoints, the project successfully produced a model capable of generating concise, SOAP-style pediatric clinical summaries. The workflow reinforced the importance of data quality, iterative testing, and the monitoring of training metrics as key components of responsible AI development in healthcare.\n",
    "\n",
    "While only the pediatric model reached completion during this phase, the results highlight the strong potential for expanding this framework to other medical domains. The next step will involve fine-tuning additional specialty models‚Äîbeginning with Oncology, followed by Cardiology and Neurology to ensure each system is optimized for its unique terminology and documentation requirements. Ultimately, this multi-specialty expansion could form the foundation for an intelligent, domain-adaptive documentation assistant that integrates seamlessly into EHR systems like Epic, improving both clinical efficiency and note accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de49c01c-8d3f-4e59-88ff-026ab7379395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Allis\\\\Downloads'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
